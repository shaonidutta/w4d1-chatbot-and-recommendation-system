# Pinecone Configuration
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=us-east-1-aws  # or your preferred region

# OpenAI Configuration (for embeddings and chat)
OPENAI_API_KEY=your_openai_api_key_here

# Index Configuration
PINECONE_INDEX_NAME=mcp-knowledge-base
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSION=1536

# Chat Configuration
CHAT_MODEL=gpt-4o-mini
MAX_TOKENS=1000          # Response length limit (1000 = ~750 words, safe & cost-effective)
TEMPERATURE=0.7          # Creativity level (0.0=factual, 1.0=creative, 0.7=balanced)

# Alternative configurations for different use cases:
# For strict factual responses: TEMPERATURE=0.2, MAX_TOKENS=800
# For creative explanations: TEMPERATURE=0.9, MAX_TOKENS=1500
# For short answers: TEMPERATURE=0.5, MAX_TOKENS=500
