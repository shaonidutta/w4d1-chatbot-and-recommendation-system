# ğŸ¤– MCP Q&A Chatbot

A sophisticated Q&A chatbot specialized in Model Context Protocol (MCP) with enhanced RAG (Retrieval-Augmented Generation) capabilities, beautiful animations, and modern UI.

## âœ¨ Features

### ğŸ¯ **Core Functionality**
- **Expert MCP Knowledge**: Comprehensive understanding of Model Context Protocol
- **Enhanced RAG System**: Multi-strategy retrieval with 0.8+ similarity scores
- **Specialized Chat Types**: General, Implementation, Troubleshooting, Concepts
- **Source Attribution**: Shows which documents were used in responses
- **Real-time Responses**: Fast, accurate answers with token usage tracking

### ğŸ¨ **Beautiful UI/UX**
- **Smooth Animations**: Three.js background with floating geometric shapes
- **Gentle Hover Effects**: Soft shadows and scale transforms
- **Subtle Gradients**: Elegant color transitions throughout
- **Glass Morphism**: Modern backdrop blur effects
- **Responsive Design**: Works perfectly on mobile and desktop

### ğŸ”§ **Advanced Features**
- **Chat History**: Save and load previous conversations
- **Settings Panel**: Customize appearance and behavior
- **Quick Questions**: Pre-defined MCP topic buttons
- **Error Handling**: Graceful fallbacks and connection monitoring
- **Export Functionality**: Download chat sessions as JSON

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Node.js 16+
- Pinecone account
- OpenAI API key

### 1. Backend Setup

```bash
# Navigate to backend
cd backend

# Install dependencies
pip install -r requirements-vector.txt

# Configure environment
cp .env.example .env
# Edit .env with your API keys

# Process data
python scripts/prepare_data_langchain.py

# Setup vector database
python scripts/setup_langchain_pinecone.py

# Start API server
python src/api.py
```

### 2. Frontend Setup

```bash
# Navigate to frontend
cd frontend

# Install dependencies
npm install

# Start development server
npm run dev
```

### 3. Access the Application

- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

## ğŸ“ Project Structure

```
QnA Chatbot-MCP Server/
â”œâ”€â”€ ğŸ“ backend/                    # Backend API & RAG system
â”‚   â”œâ”€â”€ ğŸ“ src/                    
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ langchain_rag.py    # Enhanced RAG system
â”‚   â”‚   â””â”€â”€ ğŸ“„ api.py              # FastAPI server
â”‚   â”œâ”€â”€ ğŸ“ scripts/                # Data processing scripts
â”‚   â””â”€â”€ ğŸ“„ .env                    # API keys (secured)
â”œâ”€â”€ ğŸ“ frontend/                   # React frontend
â”‚   â”œâ”€â”€ ğŸ“ src/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ components/         # UI components
â”‚   â”‚   â”œâ”€â”€ ğŸ“ utils/              # API utilities
â”‚   â”‚   â””â”€â”€ ğŸ“„ App.jsx             # Main application
â”‚   â””â”€â”€ ğŸ“„ package.json
â”œâ”€â”€ ğŸ“ data/                       # Knowledge base source
â”œâ”€â”€ ğŸ“ processed_data/             # LangChain processed chunks
â””â”€â”€ ğŸ“„ README.md                   # This file
```

## ğŸ”§ Configuration

### Backend Environment Variables

```env
# Pinecone Configuration
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_ENVIRONMENT=us-east-1-aws
PINECONE_INDEX_NAME=mcp-knowledge-base

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key
EMBEDDING_MODEL=text-embedding-3-small
CHAT_MODEL=gpt-4o-mini

# Chat Configuration
MAX_TOKENS=1000
TEMPERATURE=0.7
```

### Frontend Environment Variables

```env
# API Configuration
VITE_API_URL=http://localhost:8000

# Feature Flags
VITE_ENABLE_THREE_BACKGROUND=true
VITE_ENABLE_ANIMATIONS=true
```

## ğŸ¯ Usage Examples

### Basic Chat
```javascript
// Send a general question
POST /chat
{
  "query": "What is MCP?",
  "chat_type": "general"
}
```

### Implementation Help
```javascript
// Get implementation guidance
POST /chat
{
  "query": "How do I create an MCP server?",
  "chat_type": "implementation"
}
```

### Troubleshooting
```javascript
// Get troubleshooting help
POST /chat
{
  "query": "My MCP server won't connect",
  "chat_type": "troubleshooting"
}
```

## ğŸ“Š Performance Metrics

- **Response Time**: 3-5 seconds average
- **Retrieval Quality**: 0.8+ similarity scores
- **Cost per Query**: ~$0.60
- **Knowledge Base**: 278 high-quality chunks
- **Topics Covered**: 8 main MCP areas

## ğŸ› ï¸ Development

### Adding New Content
1. Add markdown files to `data/curated-content/`
2. Run `python scripts/prepare_data_langchain.py`
3. Run `python scripts/setup_langchain_pinecone.py`

### Customizing UI
- Edit components in `frontend/src/components/`
- Modify animations in `frontend/src/components/ThreeBackground.jsx`
- Update styles in `frontend/src/index.css`

### API Endpoints
- `POST /chat` - Main chat functionality
- `GET /health` - System health check
- `GET /topics` - Available question topics
- `POST /search` - Direct document search

## ğŸ”’ Security

- âœ… API keys stored in environment variables only
- âœ… CORS properly configured
- âœ… Input validation with Pydantic
- âœ… Error handling without exposing internals
- âœ… Rate limiting ready for production

## ğŸš€ Deployment

### Frontend (Vercel/Netlify)
```bash
npm run build
# Deploy dist/ folder
```

### Backend (Railway/Render)
```bash
# Set environment variables
# Deploy backend/ folder
```

## ğŸ“ˆ Monitoring

- **Health Endpoint**: `/health`
- **System Stats**: `/stats`
- **Token Usage**: Tracked per request
- **Error Logging**: Comprehensive error handling

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- **LangChain**: For the excellent RAG framework
- **Pinecone**: For the vector database
- **OpenAI**: For embeddings and chat completions
- **Three.js**: For beautiful 3D animations
- **Tailwind CSS**: For the styling system

---

**Built with â¤ï¸ for the MCP community**
